# lmcache_config.yaml -- Chapter 18 NIXL configuration with sizing/security notes.

prefill_server:
  enable_nixl: true
  nixl_role: sender
  nixl_receiver_host: decode-host
  nixl_receiver_port: 55555
  nixl_buffer_size: 2147483648  # size in bytes; match kv footprint (tokens * heads * head_dim * dtype)
  nixl_buffer_device: cuda
  nixl_timeout_ms: 5000
  nixl_max_retries: 3
  nixl_tls_enabled: true
  nixl_tls_cert: /etc/nixl/certs/prefill.cert
  nixl_tls_key: /etc/nixl/certs/prefill.key
  model_path: models/llama-70b
  tensor_parallel_size: 2
  max_batch_size: 32
  max_seq_len: 4096

decode_server:
  enable_nixl: true
  nixl_role: receiver
  nixl_receiver_port: 55555
  nixl_buffer_size: 2147483648
  nixl_buffer_device: cuda
  nixl_tls_ca_cert: /etc/nixl/certs/ca.pem
  kv_cache_dtype: fp16
  max_cached_tokens: 1048576
  model_path: models/llama-70b
  tensor_parallel_size: 1
  max_batch_size: 128
  nixl_gpu_selector: uuid:GPU-1234abcd

cluster:
  prefill_workers:
    - host: prefill-node-1
      port: 8000
      gpu_uuid: GPU-1111
    - host: prefill-node-2
      port: 8000
      gpu_uuid: GPU-2222
  decode_workers:
    - host: decode-node-1
      port: 8001
      gpu_uuid: GPU-3333
    - host: decode-node-2
      port: 8001
      gpu_uuid: GPU-4444

routing:
  strategy: latency_aware
  prefill_length_threshold: 100
  latency_cost_weights:
    memory_occupancy: 0.7
    active_requests: 0.3

monitoring:
  enable_metrics: true
  metrics_port: 9090
  prometheus:
    enabled: true
    endpoint: /metrics

optimizations:
  enable_zero_copy: true
  use_rdma_write: true
  kv_cache_quantization: fp16
  overlap_compute_transfer: true

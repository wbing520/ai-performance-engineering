# PyTorch 2.8 nightly with CUDA 12.9 support (latest)
--find-links https://download.pytorch.org/whl/torch_stable.html
torch==2.8.0+cu129
torchvision==0.23.0+cu129
torchaudio==2.8.0+cu129

# CUDA 12.9 runtime libraries
nvidia-cuda-runtime-cu12==12.9.140
nvidia-cudnn-cu12==9.0.0.29
nvidia-cublas-cu12==12.9.2.65
nvidia-cufft-cu12==11.2.2.12
nvidia-curand-cu12==10.4.0.141
nvidia-cusolver-cu12==12.2.0.141
nvidia-cusparse-cu12==12.3.0.141
nvidia-nccl-cu12==2.20.5
nvidia-nvtx-cu12==12.9.140

# Triton 3.4 for custom GPU kernels (latest)
triton==3.4.0

# NVIDIA libraries for profiling and optimization (latest)
nvidia-ml-py3==11.525.84
pynvml==11.5.3

# Performance monitoring and profiling (latest)
psutil==6.1.0
numpy==1.26.4
pandas==2.2.1
GPUtil==1.4.0

# Jupyter for interactive development (latest)
jupyter==1.0.0
jupyterlab==4.3.3

# Visualization for profiling results (latest)
matplotlib==3.8.4
seaborn==0.13.2
tensorboard==2.16.2
wandb==0.17.0

# Development and testing tools (latest)
pytest==8.3.4
black==24.2.0
isort==5.13.2
mypy==1.9.0

# Memory profiling (latest)
memory-profiler==0.61.0
py-spy==0.3.14
line-profiler==4.1.2

# Additional optimization libraries (latest)
einops==0.8.0  # Tensor operations
functorch==2.0.0  # Function transformations

# System utilities for performance monitoring
py-cpuinfo==9.0.0

# Optional: Advanced profiling tools
# Install system packages: nvidia-nsight-systems, nvidia-nsight-compute
# Install system packages: numactl, nvidia-container-toolkit, infiniband-diags, perftest

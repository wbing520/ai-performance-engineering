op0_op1_op3_op4_op6_op7_op9_op11_op13: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
op0_op1_op3_op4_op6_op7_op9_op11_op13.writes = 
    [   MemoryDep('buf0', c0, {c0: 2048}),
        MemoryDep('buf1', c0, {c0: 2048}),
        MemoryDep('buf11', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048}),
        MemoryDep('buf13', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048}),
        MemoryDep('buf3', c0, {c0: 2048}),
        MemoryDep('buf4', c0, {c0: 2048}),
        MemoryDep('buf6', c0, {c0: 2048}),
        MemoryDep('buf7', c0, {c0: 2048}),
        MemoryDep('buf9', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op0_op1_op3_op4_op6_op7_op9_op11_op13.unmet_dependencies = []
op0_op1_op3_op4_op6_op7_op9_op11_op13.met_dependencies = 
    [   MemoryDep('arg0_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg1_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg2_1', c0, {c0: 4194304})]
op0_op1_op3_op4_op6_op7_op9_op11_op13.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf0.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False)]
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf1.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False)]
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf3.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False)]
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf4.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False)]
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf6.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
    buf7: ComputedBuffer
    buf7.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf7.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
    buf9.users = [NodeUser(node=SchedulerNode(name='op10'), can_inplace=False, is_weak=False)]
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
    buf11.users = [NodeUser(node=SchedulerNode(name='op12'), can_inplace=False, is_weak=False)]
    buf13: ComputedBuffer
    buf13.layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
    buf13.users = [NodeUser(node=SchedulerNode(name='op14'), can_inplace=False, is_weak=False)]
]
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[0] =
op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: 2048})]
op0.unmet_dependencies = []
op0.met_dependencies = [MemoryDep('arg2_1', c0, {c0: 4194304})]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf0.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False)]
]
op0.group.device = cuda:0
op0.group.iteration = (2048, 2048)
op0.sizes = ([2048], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op0_loop_body:
    var_ranges = {p0: 2048, p1: 2048}
    index0 = 2048*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf0', get_index_1, getitem)
        return store_reduction
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[1] =
op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 2048})]
op1.unmet_dependencies = []
op1.met_dependencies = [MemoryDep('arg2_1', c0, {c0: 4194304})]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf1.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (2048, 2048)
op1.sizes = ([2048], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op1_loop_body:
    var_ranges = {p0: 2048, p1: 2048}
    index0 = 2048*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf1', get_index_1, getitem_1)
        return store_reduction
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[2] =
op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: 2048})]
op3.unmet_dependencies = []
op3.met_dependencies = [MemoryDep('arg2_1', c0, {c0: 4194304})]
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf3.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False)]
]
op3.group.device = cuda:0
op3.group.iteration = (2048, 2048)
op3.sizes = ([2048], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf3_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op3_loop_body:
    var_ranges = {p0: 2048, p1: 2048}
    index0 = 2048*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf3', get_index_1, getitem)
        return store_reduction
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[3] =
op4: SchedulerNode(ComputedBuffer)
op4.writes = [MemoryDep('buf4', c0, {c0: 2048})]
op4.unmet_dependencies = []
op4.met_dependencies = [MemoryDep('arg2_1', c0, {c0: 4194304})]
op4.outputs = [
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf4.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False)]
]
op4.group.device = cuda:0
op4.group.iteration = (2048, 2048)
op4.sizes = ([2048], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf4_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op4_loop_body:
    var_ranges = {p0: 2048, p1: 2048}
    index0 = 2048*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf4', get_index_1, getitem_1)
        return store_reduction
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[4] =
op6: SchedulerNode(ComputedBuffer)
op6.writes = [MemoryDep('buf6', c0, {c0: 2048})]
op6.unmet_dependencies = []
op6.met_dependencies = [MemoryDep('arg2_1', c0, {c0: 4194304})]
op6.outputs = [
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf6.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
]
op6.group.device = cuda:0
op6.group.iteration = (2048, 2048)
op6.sizes = ([2048], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf6_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op6_loop_body:
    var_ranges = {p0: 2048, p1: 2048}
    index0 = 2048*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf6', get_index_1, getitem)
        return store_reduction
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[5] =
op7: SchedulerNode(ComputedBuffer)
op7.writes = [MemoryDep('buf7', c0, {c0: 2048})]
op7.unmet_dependencies = []
op7.met_dependencies = [MemoryDep('arg2_1', c0, {c0: 4194304})]
op7.outputs = [
    buf7: ComputedBuffer
    buf7.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf7.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
]
op7.group.device = cuda:0
op7.group.iteration = (2048, 2048)
op7.sizes = ([2048], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf7_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op7_loop_body:
    var_ranges = {p0: 2048, p1: 2048}
    index0 = 2048*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', load)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf7', get_index_1, getitem_1)
        return store_reduction
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[6] =
op9: SchedulerNode(ComputedBuffer)
op9.writes = [MemoryDep('buf9', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op9.unmet_dependencies = [MemoryDep('buf0', c0, {c0: 2048}), MemoryDep('buf1', c0, {c0: 2048})]
op9.met_dependencies = 
    [   MemoryDep('arg0_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg1_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg2_1', c0, {c0: 4194304})]
op9.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
    buf9.users = [NodeUser(node=SchedulerNode(name='op10'), can_inplace=False, is_weak=False)]
]
op9.group.device = cuda:0
op9.group.iteration = (4194304, 1)
op9.sizes = ([4, 512, 2048], [])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf0_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
buf1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
arg0_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf9_layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
class op9_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 512*p0 + p1
    index2 = p2
    index3 = 2048*p0 + 8192*p1 + p2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf0', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf1', get_index_2)
        constant = ops.constant(2048.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('arg0_1', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('arg1_1', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index3')
        store = ops.store('buf9', get_index_5, add_1, None)
        return store
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[7] =
op11: SchedulerNode(ComputedBuffer)
op11.writes = [MemoryDep('buf11', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op11.unmet_dependencies = [MemoryDep('buf3', c0, {c0: 2048}), MemoryDep('buf4', c0, {c0: 2048})]
op11.met_dependencies = 
    [   MemoryDep('arg0_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg1_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg2_1', c0, {c0: 4194304})]
op11.outputs = [
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
    buf11.users = [NodeUser(node=SchedulerNode(name='op12'), can_inplace=False, is_weak=False)]
]
op11.group.device = cuda:0
op11.group.iteration = (4194304, 1)
op11.sizes = ([4, 512, 2048], [])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf3_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
buf4_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
arg0_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf11_layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
class op11_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 512*p0 + p1
    index2 = p2
    index3 = 2048*p0 + 8192*p1 + p2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf3', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf4', get_index_2)
        constant = ops.constant(2048.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('arg0_1', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('arg1_1', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index3')
        store = ops.store('buf11', get_index_5, add_1, None)
        return store
op0_op1_op3_op4_op6_op7_op9_op11_op13.snodes[8] =
op13: SchedulerNode(ComputedBuffer)
op13.writes = [MemoryDep('buf13', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op13.unmet_dependencies = [MemoryDep('buf6', c0, {c0: 2048}), MemoryDep('buf7', c0, {c0: 2048})]
op13.met_dependencies = 
    [   MemoryDep('arg0_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg1_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg2_1', c0, {c0: 4194304})]
op13.outputs = [
    buf13: ComputedBuffer
    buf13.layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
    buf13.users = [NodeUser(node=SchedulerNode(name='op14'), can_inplace=False, is_weak=False)]
]
op13.group.device = cuda:0
op13.group.iteration = (4194304, 1)
op13.sizes = ([4, 512, 2048], [])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf6_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
buf7_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
arg0_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
arg1_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf13_layout = FixedLayout('cuda:0', torch.float32, size=[512, 4, 2048], stride=[8192, 2048, 1])
class op13_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 512*p0 + p1
    index2 = p2
    index3 = 2048*p0 + 8192*p1 + p2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf6', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf7', get_index_2)
        constant = ops.constant(2048.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('arg0_1', get_index_3)
        mul_1 = ops.mul(mul, load_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('arg1_1', get_index_4)
        add_1 = ops.add(mul_1, load_4)
        get_index_5 = self.get_index('index3')
        store = ops.store('buf13', get_index_5, add_1, None)
        return store


op10: ExternKernelSchedulerNode(ExternKernelOut)
op10.writes = [StarDep(name='buf10', mode=None)]
op10.unmet_dependencies = [StarDep(name='buf9', mode=None)]
op10.met_dependencies = [StarDep(name='arg3_1', mode=None)]
op10.outputs = [
    buf10: ExternKernelOut
    buf10.layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
    buf10.users = [NodeUser(node=SchedulerNode(name='op15'), can_inplace=True, is_weak=False)]
]
op10.node.kernel = extern_kernels.mm


op12: ExternKernelSchedulerNode(ExternKernelOut)
op12.writes = [StarDep(name='buf12', mode=None)]
op12.unmet_dependencies = [StarDep(name='buf11', mode=None)]
op12.met_dependencies = [StarDep(name='arg3_1', mode=None)]
op12.outputs = [
    buf12: ExternKernelOut
    buf12.layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
    buf12.users = [NodeUser(node=SchedulerNode(name='op16'), can_inplace=True, is_weak=False)]
]
op12.node.kernel = extern_kernels.mm


op14: ExternKernelSchedulerNode(ExternKernelOut)
op14.writes = [StarDep(name='buf14', mode=None)]
op14.unmet_dependencies = [StarDep(name='buf13', mode=None)]
op14.met_dependencies = [StarDep(name='arg3_1', mode=None)]
op14.outputs = [
    buf14: ExternKernelOut
    buf14.layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
    buf14.users = [NodeUser(node=SchedulerNode(name='op17'), can_inplace=True, is_weak=False)]
]
op14.node.kernel = extern_kernels.mm


op15: SchedulerNode(ComputedBuffer)
op15.writes = [MemoryDep('buf15', c0, {c0: 4194304})]
op15.unmet_dependencies = [MemoryDep('buf10', c0, {c0: 4194304})]
op15.met_dependencies = [MemoryDep('arg4_1', ModularIndexing(c1, 1, 2048), {c0: 512, c1: 8192})]
op15.outputs = [
    buf15: ComputedBuffer
    buf15.layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
    buf15.users = [NodeUser(node=ExternKernelSchedulerNode(name='op18'), can_inplace=False, is_weak=False)]
]
op15.group.device = cuda:0
op15.group.iteration = (4194304, 1)
op15.sizes = ([512, 8192], [])
buf10_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg4_1_layout = FixedLayout('cuda:0', torch.float32, size=[6144], stride=[1])
buf15_layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
class op15_loop_body:
    var_ranges = {p0: 512, p1: 8192}
    index0 = 8192*p0 + p1
    index1 = ModularIndexing(p1, 1, 2048)
    index2 = 8192*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf10', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg4_1', get_index_1)
        add = ops.add(load, load_1)
        constant = ops.constant(0.08838834764831845, torch.float32)
        mul = ops.mul(add, constant)
        get_index_2 = self.get_index('index2')
        store = ops.store('buf15', get_index_2, mul, None)
        return store


op16: SchedulerNode(ComputedBuffer)
op16.writes = [MemoryDep('buf16', c0, {c0: 4194304})]
op16.unmet_dependencies = [MemoryDep('buf12', c0, {c0: 4194304})]
op16.met_dependencies = [   MemoryDep('arg4_1', (ModularIndexing(c1, 1, 2048)) + 2048, {c0: 512, c1: 8192})]
op16.outputs = [
    buf16: ComputedBuffer
    buf16.layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
    buf16.users = [NodeUser(node=ExternKernelSchedulerNode(name='op18'), can_inplace=False, is_weak=False)]
]
op16.group.device = cuda:0
op16.group.iteration = (4194304, 1)
op16.sizes = ([512, 8192], [])
buf12_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg4_1_layout = FixedLayout('cuda:0', torch.float32, size=[6144], stride=[1])
buf16_layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
class op16_loop_body:
    var_ranges = {p0: 512, p1: 8192}
    index0 = 8192*p0 + p1
    index1 = (ModularIndexing(p1, 1, 2048)) + 2048
    index2 = 8192*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf12', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg4_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index2')
        store = ops.store('buf16', get_index_2, add, None)
        return store


op17: SchedulerNode(ComputedBuffer)
op17.writes = [MemoryDep('buf17', c0, {c0: 4194304})]
op17.unmet_dependencies = [MemoryDep('buf14', c0, {c0: 4194304})]
op17.met_dependencies = [   MemoryDep('arg4_1', (ModularIndexing(c1, 1, 2048)) + 4096, {c0: 512, c1: 8192})]
op17.outputs = [
    buf17: ComputedBuffer
    buf17.layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
    buf17.users = [NodeUser(node=ExternKernelSchedulerNode(name='op18'), can_inplace=False, is_weak=False)]
]
op17.group.device = cuda:0
op17.group.iteration = (4194304, 1)
op17.sizes = ([512, 8192], [])
buf14_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg4_1_layout = FixedLayout('cuda:0', torch.float32, size=[6144], stride=[1])
buf17_layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
class op17_loop_body:
    var_ranges = {p0: 512, p1: 8192}
    index0 = 8192*p0 + p1
    index1 = (ModularIndexing(p1, 1, 2048)) + 4096
    index2 = 8192*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf14', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg4_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index2')
        store = ops.store('buf17', get_index_2, add, None)
        return store


op18: ExternKernelSchedulerNode(FallbackKernel)
op18.writes = [StarDep(name='buf18', mode=None)]
op18.unmet_dependencies = 
    [   StarDep(name='buf15', mode=None),
        StarDep(name='buf16', mode=None),
        StarDep(name='buf17', mode=None)]
op18.met_dependencies = []
op18.outputs = [
    buf18: FallbackKernel
    buf18.layout = MultiOutputLayout(device=device(type='cuda', index=0))
    buf18.users = [NodeUser(node=ExternKernelSchedulerNode(name='op19'), can_inplace=False, is_weak=False)]
]
op18.node.kernel = torch.ops.aten._scaled_dot_product_efficient_attention.default


op19: ExternKernelSchedulerNode(MultiOutput)
op19.writes = [StarDep(name='buf19', mode=None)]
op19.unmet_dependencies = [StarDep(name='buf18', mode=None)]
op19.met_dependencies = []
op19.outputs = [
    buf19: MultiOutput
    buf19.layout = FixedLayout('cuda:0', torch.float32, size=[1, 64, 512, 128], stride=[4194304, 128, 8192, 1])
    buf19.users = [NodeUser(node=SchedulerNode(name='op23'), can_inplace=False, is_weak=False)]
]
op19.node.kernel = None


op23: ExternKernelSchedulerNode(ExternKernelOut)
op23.writes = [StarDep(name='buf23', mode=None)]
op23.unmet_dependencies = [StarDep(name='buf19', mode=None)]
op23.met_dependencies = [StarDep(name='arg5_1', mode=None)]
op23.outputs = [
    buf23: ExternKernelOut
    buf23.layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
    buf23.users = [
        NodeUser(node=SchedulerNode(name='op24'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op25'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op31'), can_inplace=False, is_weak=False),
    ]
]
op23.node.kernel = extern_kernels.mm


op24_op25_op27: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op24_op25_op27.writes = 
    [   MemoryDep('buf24', c0, {c0: 2048}),
        MemoryDep('buf25', c0, {c0: 2048}),
        MemoryDep('buf27', c0, {c0: 4194304})]
op24_op25_op27.unmet_dependencies = [MemoryDep('buf23', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op24_op25_op27.met_dependencies = 
    [   MemoryDep('arg2_1', c0, {c0: 4194304}),
        MemoryDep('arg6_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg7_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg8_1', c1, {c0: 2048, c1: 2048})]
op24_op25_op27.outputs = [
    buf24: ComputedBuffer
    buf24.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf24.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False)]
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf25.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False)]
    buf27: ComputedBuffer
    buf27.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
    buf27.users = [NodeUser(node=SchedulerNode(name='op28'), can_inplace=False, is_weak=False)]
]
op24_op25_op27.snodes[0] =
op24: SchedulerNode(ComputedBuffer)
op24.writes = [MemoryDep('buf24', c0, {c0: 2048})]
op24.unmet_dependencies = [MemoryDep('buf23', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op24.met_dependencies = 
    [   MemoryDep('arg2_1', c0, {c0: 4194304}),
        MemoryDep('arg6_1', c1, {c0: 2048, c1: 2048})]
op24.outputs = [
    buf24: ComputedBuffer
    buf24.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf24.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False)]
]
op24.group.device = cuda:0
op24.group.iteration = (2048, 2048)
op24.sizes = ([4, 512], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg6_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf24_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op24_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 2048*p0 + 8192*p1 + p2
    index2 = p2
    index3 = 512*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf23', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg6_1', get_index_2)
        add = ops.add(load_1, load_2)
        add_1 = ops.add(load, add)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', add_1)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_3 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf24', get_index_3, getitem)
        return store_reduction
op24_op25_op27.snodes[1] =
op25: SchedulerNode(ComputedBuffer)
op25.writes = [MemoryDep('buf25', c0, {c0: 2048})]
op25.unmet_dependencies = [MemoryDep('buf23', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048})]
op25.met_dependencies = 
    [   MemoryDep('arg2_1', c0, {c0: 4194304}),
        MemoryDep('arg6_1', c1, {c0: 2048, c1: 2048})]
op25.outputs = [
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
    buf25.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False)]
]
op25.group.device = cuda:0
op25.group.iteration = (2048, 2048)
op25.sizes = ([4, 512], [2048])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg6_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf25_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
class op25_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 2048*p0 + 8192*p1 + p2
    index2 = p2
    index3 = 512*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf23', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg6_1', get_index_2)
        add = ops.add(load_1, load_2)
        add_1 = ops.add(load, add)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', add_1)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_3 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf25', get_index_3, getitem_1)
        return store_reduction
op24_op25_op27.snodes[2] =
op27: SchedulerNode(ComputedBuffer)
op27.writes = [MemoryDep('buf27', c0, {c0: 4194304})]
op27.unmet_dependencies = 
    [   MemoryDep('buf23', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048}),
        MemoryDep('buf24', c0, {c0: 2048}),
        MemoryDep('buf25', c0, {c0: 2048})]
op27.met_dependencies = 
    [   MemoryDep('arg2_1', c0, {c0: 4194304}),
        MemoryDep('arg6_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg7_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg8_1', c1, {c0: 2048, c1: 2048})]
op27.outputs = [
    buf27: ComputedBuffer
    buf27.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
    buf27.users = [NodeUser(node=SchedulerNode(name='op28'), can_inplace=False, is_weak=False)]
]
op27.group.device = cuda:0
op27.group.iteration = (4194304, 1)
op27.sizes = ([4, 512, 2048], [])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg6_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf24_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
buf25_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 1], stride=[512, 1, 2048])
arg7_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
arg8_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf27_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
class op27_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 2048*p0 + 8192*p1 + p2
    index2 = p2
    index3 = 512*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf23', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg6_1', get_index_2)
        add = ops.add(load_1, load_2)
        add_1 = ops.add(load, add)
        get_index_3 = self.get_index('index3')
        load_3 = ops.load('buf24', get_index_3)
        sub = ops.sub(add_1, load_3)
        get_index_4 = self.get_index('index3')
        load_4 = ops.load('buf25', get_index_4)
        constant = ops.constant(2048.0, torch.float32)
        truediv = ops.truediv(load_4, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add_2 = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add_2)
        mul = ops.mul(sub, rsqrt)
        get_index_5 = self.get_index('index2')
        load_5 = ops.load('arg7_1', get_index_5)
        mul_1 = ops.mul(mul, load_5)
        get_index_6 = self.get_index('index2')
        load_6 = ops.load('arg8_1', get_index_6)
        add_3 = ops.add(mul_1, load_6)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf27', get_index_7, add_3, None)
        return store


op28: ExternKernelSchedulerNode(ExternKernelOut)
op28.writes = [StarDep(name='buf28', mode=None)]
op28.unmet_dependencies = [StarDep(name='buf27', mode=None)]
op28.met_dependencies = [StarDep(name='arg9_1', mode=None)]
op28.outputs = [
    buf28: ExternKernelOut
    buf28.layout = FixedLayout('cuda:0', torch.float32, size=[2048, 8192], stride=[8192, 1])
    buf28.users = [NodeUser(node=SchedulerNode(name='op29'), can_inplace=True, is_weak=False)]
]
op28.node.kernel = extern_kernels.mm


op29: SchedulerNode(ComputedBuffer)
op29.writes = [MemoryDep('buf29', c0, {c0: 16777216})]
op29.unmet_dependencies = [MemoryDep('buf28', c0, {c0: 16777216})]
op29.met_dependencies = [MemoryDep('arg10_1', c1, {c0: 2048, c1: 8192})]
op29.outputs = [
    buf29: ComputedBuffer
    buf29.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 8192], stride=[4194304, 8192, 1])
    buf29.users = [NodeUser(node=SchedulerNode(name='op30'), can_inplace=False, is_weak=False)]
]
op29.group.device = cuda:0
op29.group.iteration = (16777216, 1)
op29.sizes = ([2048, 8192], [])
buf28_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 8192], stride=[8192, 1])
arg10_1_layout = FixedLayout('cuda:0', torch.float32, size=[8192], stride=[1])
buf29_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 8192], stride=[4194304, 8192, 1])
class op29_loop_body:
    var_ranges = {p0: 2048, p1: 8192}
    index0 = 8192*p0 + p1
    index1 = p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf28', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg10_1', get_index_1)
        add = ops.add(load, load_1)
        constant = ops.constant(0.5, torch.float32)
        mul = ops.mul(add, constant)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf28', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg10_1', get_index_3)
        add_1 = ops.add(load_2, load_3)
        constant_1 = ops.constant(0.7071067811865476, torch.float32)
        mul_1 = ops.mul(add_1, constant_1)
        erf = ops.erf(mul_1)
        constant_2 = ops.constant(1.0, torch.float32)
        add_2 = ops.add(erf, constant_2)
        mul_2 = ops.mul(mul, add_2)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf29', get_index_4, mul_2, None)
        return store


op30: ExternKernelSchedulerNode(ExternKernelOut)
op30.writes = [StarDep(name='buf30', mode=None)]
op30.unmet_dependencies = [StarDep(name='buf29', mode=None)]
op30.met_dependencies = [StarDep(name='arg11_1', mode=None)]
op30.outputs = [
    buf30: ExternKernelOut
    buf30.layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
    buf30.users = [NodeUser(node=SchedulerNode(name='op31'), can_inplace=True, is_weak=False)]
]
op30.node.kernel = extern_kernels.mm


op31: SchedulerNode(ComputedBuffer)
op31.writes = [MemoryDep('buf31', c0, {c0: 4194304})]
op31.unmet_dependencies = 
    [   MemoryDep('buf23', 2048*c0 + 8192*c1 + c2, {c0: 4, c1: 512, c2: 2048}),
        MemoryDep('buf30', c0, {c0: 4194304})]
op31.met_dependencies = 
    [   MemoryDep('arg12_1', c1, {c0: 2048, c1: 2048}),
        MemoryDep('arg2_1', c0, {c0: 4194304}),
        MemoryDep('arg6_1', c1, {c0: 2048, c1: 2048})]
op31.outputs = [
    buf31: ComputedBuffer
    buf31.layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
    buf31.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op31.group.device = cuda:0
op31.group.iteration = (4194304, 1)
op31.sizes = ([4, 512, 2048], [])
arg2_1_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg6_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf30_layout = FixedLayout('cuda:0', torch.float32, size=[2048, 2048], stride=[2048, 1])
arg12_1_layout = FixedLayout('cuda:0', torch.float32, size=[2048], stride=[1])
buf31_layout = FixedLayout('cuda:0', torch.float32, size=[4, 512, 2048], stride=[1048576, 2048, 1])
class op31_loop_body:
    var_ranges = {p0: 4, p1: 512, p2: 2048}
    index0 = 1048576*p0 + 2048*p1 + p2
    index1 = 2048*p0 + 8192*p1 + p2
    index2 = p2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf23', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg6_1', get_index_2)
        add = ops.add(load_1, load_2)
        add_1 = ops.add(load, add)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf30', get_index_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('arg12_1', get_index_4)
        add_2 = ops.add(load_3, load_4)
        add_3 = ops.add(add_1, add_2)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf31', get_index_5, add_3, None)
        return store



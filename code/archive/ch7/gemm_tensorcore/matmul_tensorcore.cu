#include <mma.h>
#include <cuda_runtime.h>
using namespace nvcuda;

#define TILE_DIM 16

__global__ void matmul_tensorcore(const half* A, const half* B, float* C, int N) {
    int warpM = (blockIdx.y * blockDim.y + threadIdx.y) / 32;
    int warpN = (blockIdx.x * blockDim.x + threadIdx.x) / 32;

    wmma::fragment<wmma::matrix_a, TILE_DIM, TILE_DIM, TILE_DIM, half, wmma::row_major> a_frag;
    wmma::fragment<wmma::matrix_b, TILE_DIM, TILE_DIM, TILE_DIM, half, wmma::col_major> b_frag;
    wmma::fragment<wmma::accumulator, TILE_DIM, TILE_DIM, TILE_DIM, float> acc_frag;
    wmma::fill_fragment(acc_frag, 0.0f);

    for (int k = 0; k < N; k += TILE_DIM) {
        int aRow = warpM * TILE_DIM, aCol = k;
        int bRow = k, bCol = warpN * TILE_DIM;
        wmma::load_matrix_sync(a_frag, A + aRow * N + aCol, N);
        wmma::load_matrix_sync(b_frag, B + bRow * N + bCol, N);
        wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
    }

    int cRow = warpM * TILE_DIM, cCol = warpN * TILE_DIM;
    wmma::store_matrix_sync(C + cRow * N + cCol, acc_frag, N, wmma::mem_row_major);
}

int main() {
    const int N = 1024;
    size_t size = N * N * sizeof(half);
    half *h_A = new half[N*N], *h_B = new half[N*N];
    float *h_C = new float[N*N];
    half *d_A, *d_B; float *d_C;
    cudaMalloc(&d_A, size); cudaMalloc(&d_B, size); cudaMalloc(&d_C, N*N*sizeof(float));
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    dim3 block(32,32), grid((N+31)/32,(N+31)/32);
    matmul_tensorcore<<<grid, block>>>(d_A, d_B, d_C, N);
    cudaDeviceSynchronize();
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    delete[] h_A; delete[] h_B; delete[] h_C;
    return 0;
}

/**
 * Thread Block Clusters for Blackwell
 * ====================================
 * 
 * Blackwell SM 10.0 provides enhanced Thread Block Cluster support:
 * - Up to 8 CTAs per cluster (vs 4 on Hopper)
 * - Distributed Shared Memory (DSMEM) - 2 MB total
 * - Better scheduling for 192 SMs
 * - Cluster-wide synchronization
 * 
 * Key Benefits:
 * - Increased parallelism
 * - Shared data across thread blocks
 * - Reduced global memory traffic
 * 
 * Requirements: SM 10.0 (Blackwell), CUDA 13.0+
 * 
 * Compile:
 *   nvcc -O3 -std=c++17 -arch=sm_100 cluster_group_blackwell.cu -o cluster_group
 * 
 * Performance on B200:
 * - Up to 8 CTAs per cluster
 * - 2 MB distributed shared memory
 * - Better load balancing on 192 SMs
 */

#include <cooperative_groups.h>
#include <cuda_runtime.h>
#include <cstdio>
#include <vector>

namespace cg = cooperative_groups;

// Kernel that sums values across blocks in a cluster using block-scoped shared arrays
__global__ void cluster_sum_kernel(const float *in, float *out, int elems_per_block) {
    cg::cluster_group cluster = cg::this_cluster();
    cg::thread_block cta = cg::this_thread_block();

    extern __shared__ float sdata[]; // per-CTA shared buffer

    float sum = 0.0f;
    int base = blockIdx.x * elems_per_block;
    for (int i = threadIdx.x; i < elems_per_block; i += blockDim.x) {
        sum += in[base + i];
    }

    sdata[threadIdx.x] = sum;
    cta.sync();
    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
        if (threadIdx.x < stride) {
            sdata[threadIdx.x] += sdata[threadIdx.x + stride];
        }
        cta.sync();
    }

    if (threadIdx.x == 0) {
        out[blockIdx.x] = sdata[0];
    }

    cluster.sync();

    if (cluster.block_rank() == 0 && threadIdx.x == 0) {
        int cluster_blocks = cluster.dim_blocks().x * cluster.dim_blocks().y * cluster.dim_blocks().z;
        int cluster_start = blockIdx.x - cluster.block_rank();

        float cluster_total = 0.0f;
        for (int b = 0; b < cluster_blocks && (cluster_start + b) < gridDim.x; ++b) {
            cluster_total += out[cluster_start + b];
        }
        out[cluster_start] = cluster_total;
    }
}

// ============================================================================
// Blackwell Thread Block Cluster Information
// ============================================================================

void print_blackwell_cluster_info() {
    printf("\n=== Blackwell Thread Block Clusters ===\n");
    
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, 0);
    
    printf("GPU: %s\n", prop.name);
    printf("Compute Capability: %d.%d\n", prop.major, prop.minor);
    
    if (prop.major == 10 && prop.minor == 0) {
        printf("✓ Blackwell B200/B300 detected\n\n");
        
        printf("Cluster Capabilities:\n");
        printf("  Max CTAs per cluster: 8 (vs 4 on Hopper)\n");
        printf("  Distributed Shared Memory: 2 MB total\n");
        printf("  Per-block shared memory: 256 KB\n");
        printf("  Total SMs: 192 (better load balancing)\n");
        
        printf("\nBlackwell Advantages:\n");
        printf("  1. 2x more CTAs per cluster\n");
        printf("  2. Larger distributed shared memory\n");
        printf("  3. Better scheduling on 192 SMs\n");
        printf("  4. Reduced global memory traffic\n");
        
        printf("\nUse Cases:\n");
        printf("  - Large matrix operations (GEMM)\n");
        printf("  - Stencil computations\n");
        printf("  - Graph algorithms\n");
        printf("  - Sparse matrix operations\n");
        
        printf("\nProgramming Model:\n");
        printf("  1. Create cluster with cudaLaunchAttributeClusterDimension\n");
        printf("  2. Use cg::this_cluster() in kernel\n");
        printf("  3. cluster.sync() for barrier\n");
        printf("  4. cluster.block_rank() for coordination\n");
    } else {
        printf("⚠ Not Blackwell - cluster support may be limited\n");
        printf("  Blackwell SM 10.0 provides:\n");
        printf("  - 8 CTAs per cluster (vs 4)\n");
        printf("  - 2 MB distributed shared memory\n");
    }
}

int main() {
    printf("=== Thread Block Clusters on Blackwell ===\n\n");
    
    // Print cluster information
    print_blackwell_cluster_info();
    
    printf("\n=== Running Cluster Sum Example ===\n");
    
    constexpr int cluster_size = 2;
    int num_blocks = 8; // total CTAs in the grid (must be >= cluster_size)
    int elems_per_block = 1 << 20; // 1M elements per block
    int threads = 256;
    size_t total_elems = size_t(num_blocks) * elems_per_block;
    size_t bytes = total_elems * sizeof(float);

    float *d_in = nullptr, *d_out = nullptr;
    cudaMalloc(&d_in, bytes);
    cudaMalloc(&d_out, num_blocks * sizeof(float));

    std::vector<float> h_in(total_elems, 1.0f);
    cudaMemcpy(d_in, h_in.data(), bytes, cudaMemcpyHostToDevice);
    cudaMemset(d_out, 0, num_blocks * sizeof(float));

    cudaLaunchConfig_t cfg{};
    cfg.gridDim = dim3(num_blocks, 1, 1);
    cfg.blockDim = dim3(threads, 1, 1);
    cfg.dynamicSmemBytes = threads * sizeof(float);

    cudaLaunchAttribute attr[1];
    attr[0].id = cudaLaunchAttributeClusterDimension;
    attr[0].val.clusterDim.x = cluster_size;
    attr[0].val.clusterDim.y = 1;
    attr[0].val.clusterDim.z = 1;

    cfg.attrs = attr;
    cfg.numAttrs = 1;

    cudaFuncSetAttribute(cluster_sum_kernel, cudaFuncAttributeNonPortableClusterSizeAllowed, 1);

    cudaError_t err = cudaLaunchKernelEx(&cfg, cluster_sum_kernel, d_in, d_out, elems_per_block);
    if (err != cudaSuccess) {
        printf("Cluster launch not supported or failed: %s\n", cudaGetErrorString(err));
        cudaFree(d_in);
        cudaFree(d_out);
        return 0;
    }

    err = cudaDeviceSynchronize();
    if (err != cudaSuccess) {
        printf("Kernel error: %s\n", cudaGetErrorString(err));
        cudaFree(d_in);
        cudaFree(d_out);
        return -1;
    }

    std::vector<float> h_out(num_blocks, 0.0f);
    cudaMemcpy(h_out.data(), d_out, num_blocks * sizeof(float), cudaMemcpyDeviceToHost);

    double expected_block = static_cast<double>(elems_per_block);
    double expected_cluster_total = expected_block * cluster_size;

    printf("cluster_group_blackwell completed.\n");
    int sample_block = (num_blocks > 1) ? 1 : 0;
    printf(" - Partial sum (block %d): %.2f (expected %.2f)\n", sample_block, h_out[sample_block], expected_block);
    printf(" - Cluster total (cluster 0): %.2f (expected %.2f)\n", h_out[0], expected_cluster_total);

    cudaFree(d_in);
    cudaFree(d_out);
    
    printf("\n=== Summary ===\n");
    printf("✓ Thread Block Clusters with up to 8 CTAs (Blackwell)\n");
    printf("✓ Distributed Shared Memory (DSMEM) - 2 MB total\n");
    printf("✓ Cluster-wide synchronization\n");
    printf("✓ Optimized for Blackwell's 192 SMs\n");
    printf("\nBlackwell provides 2x more CTAs per cluster than Hopper!\n");
    
    return 0;
}

# AI Performance Engineering - Latest Requirements
# PyTorch 2.8 nightly, CUDA 12.8, Triton 3.4, Architecture Switching Support

# Core PyTorch ecosystem (nightly builds)
--index-url https://download.pytorch.org/whl/nightly/cu128
torch==2.8.0.dev
torch==2.8.0.dev
torch==2.8.0.dev

# CUDA and GPU acceleration (CUDA 12.8)
nvidia-cuda-runtime-cu12==12.8.*
nvidia-cuda-nvrtc-cu12==12.8.*
nvidia-cudnn-cu12==9.0.0.29
nvidia-cublas-cu12==12.8.*
nvidia-cufft-cu12==11.2.2.12
nvidia-curand-cu12==10.4.0.141
nvidia-cusolver-cu12==12.2.0.141
nvidia-cusparse-cu12==12.3.0.141
nvidia-nccl-cu12==2.20.5
nvidia-nvtx-cu12==12.8.*

# Triton for GPU kernel development (latest)
triton==3.4.0

# Performance monitoring and profiling (latest)
nvidia-ml-py3==11.525.84
psutil==6.1.0
GPUtil==1.4.0

# Distributed training (latest)
torch==2.8.0.dev
deepspeed==0.14.0
fairscale==0.4.13

# Data loading and preprocessing
numpy==1.26.4
pandas==2.2.1
scikit-learn==1.4.1
pillow==10.2.0

# Visualization and monitoring
matplotlib==3.8.4
seaborn==0.13.2
tensorboard==2.16.2
wandb==0.17.0

# System utilities
psutil==6.1.0
py-cpuinfo==9.0.0
GPUtil==1.4.0

# Development tools
jupyter==1.0.0
ipykernel==6.29.5
black==24.2.0
flake8==7.0.0
mypy==1.9.0

# Optional: Advanced features
transformers==4.40.2
datasets==2.18.0
accelerate==0.29.0
sentencepiece==0.2.0
tokenizers==0.15.2

# Optional: Model serving
torch==2.8.0.dev
torch==2.8.0.dev
torch==2.8.0.dev

# Optional: Quantization and optimization
torch==2.8.0.dev
onnx==1.16.1
onnxruntime-gpu==1.18.0

# Optional: Monitoring and debugging
py-spy==0.3.14
memory-profiler==0.61.0
line-profiler==4.1.2

# Optional: Advanced profiling and analysis
py-spy==0.3.14
memory-profiler==0.61.0
line-profiler==4.1.2
pyinstrument==5.0.0
snakeviz==2.1.1

# Optional: Machine learning and optimization
optuna==4.0.0
hyperopt==0.2.7
ray[tune]==2.10.0

# Optional: Data processing and analysis
dask==2024.1.1
vaex==4.17.0
xarray==2024.1.0

# Optional: Visualization and reporting
plotly==5.18.0
bokeh==3.4.0
dash==2.16.1

# System dependencies (install via package manager)
# - numactl (for NUMA binding)
# - nvidia-container-toolkit (for Docker GPU support)
# - nvidia-docker2 (for Docker GPU support)
# - infiniband-diags (for InfiniBand diagnostics)
# - perftest (for network performance testing)
# - nvidia-nsight-systems (latest profiling tools)
# - nvidia-nsight-compute (latest profiling tools)
# - nvidia-nsight-graphics (latest graphics profiling)
# - nvidia-nsight-systems-cli (command line profiling)
# - nvidia-nsight-compute-cli (command line profiling)

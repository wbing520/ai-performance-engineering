# AI Performance Engineering - Blackwell Requirements
# Target: Blackwell B200/B300 (SM100) with PyTorch 2.9 (cu130), CUDA 13.0, Triton 3.5.0
# All versions are pinned to exact versions for reproducible builds

# Core PyTorch ecosystem (CUDA 13 wheels).
--index-url https://download.pytorch.org/whl/cu130
--extra-index-url https://pypi.org/simple
torch==2.9.0+cu130
torchvision==0.24.0+cu130
torchaudio==2.9.0+cu130

# Optional: install upstream Triton if you author custom GPU kernels outside of
# TorchInductor (PyTorch bundles its own runtime already).
triton==3.5.0

# Build tooling compatibility
packaging>=24.0

# Monitoring and system insight
pynvml==13.0.1
psutil==7.1.0
GPUtil==1.4.0
py-cpuinfo==9.0.0

# Data processing stack
numpy==2.1.2
pandas==2.3.2
scikit-learn==1.7.2
pillow==11.3.0

# Visualization & reporting
matplotlib==3.10.6
seaborn==0.13.2
tensorboard==2.20.0
wandb==0.22.0
plotly==6.3.0
bokeh==3.8.0
dash==3.2.0

# Development workflow
jupyter==1.1.1
ipykernel==6.30.1
black==25.9.0
flake8==7.3.0
mypy==1.18.2

# Model development helpers
transformers==4.40.2
datasets==2.21.0
accelerate==0.29.0
sentencepiece==0.2.0
tokenizers==0.19.1

# Optional model serving & optimization
onnx==1.19.0
onnxruntime-gpu==1.23.0
torchtitan>=0.2.0  # Async Tensor Parallelism demos (requires CUDA build)

# Profiling & diagnostics
py-spy==0.4.1
memory-profiler==0.61.0
line-profiler==5.0.0
pyinstrument==5.1.1
snakeviz==2.2.2

# Experiment management & search
optuna==4.5.0
hyperopt==0.2.7
ray==2.49.2

# Scalable data utilities
dask==2025.9.1
xarray==2025.6.1

# Notes
# - Install DeepSpeed/Fairscale or other distributed frameworks separately as needed.
# - Ensure CUDA 13 toolkit/driver is present on systems building custom extensions.
